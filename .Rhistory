d <- 1
mycount <- mycount + 1
bigmat <- out$tau2.lambda[d,loading]*exp(-preddist/out$phi.lambda[d,loading])
A <- bigmat[condinds, condinds]
B <- bigmat[condinds, -condinds]
C <- bigmat[-condinds, -condinds]
L <- chol(A)
LB <- forwardsolve(t(L), B)
part1 <- t(backsolve(L, LB))
Ainv <- solve(A)
test1 <- t(B)%*%Ainv
dim(test1)
dim(part1)
test1[,1]
test1[1,]
cbind(test1[1,], part1[1,])
condvar <- C - part1%*%B
Lambda.tilde[d, seq(loading, out$n.factors*out$n.locs, by=out$n.factors)]
out$Lambda.tilde[d, seq(loading, out$n.factors*out$n.locs, by=out$n.factors)]
names(out)
for(d in seq(1, out$draws, by=addthin)){
mycount <- mycount + 1
bigmat <- out$tau2.lambda[d,loading]*exp(-preddist/out$phi.lambda[d,loading])
A <- bigmat[condinds, condinds]
B <- bigmat[condinds, -condinds]
C <- bigmat[-condinds, -condinds]
L <- chol(A)
LB <- forwardsolve(t(L), B)
part1 <- t(backsolve(L, LB))
condvar <- C - part1%*%B
lammean[mycount,] <- part1%*%out$Lambda.tilde[d, seq(loading, out$n.factors*out$n.locs, by=out$n.factors)] #((loading-1)*out$n.locs) + (1:out$n.locs)]
cholC <- chol(condvar)
lamresid[mycount,] <- as.numeric(cholC%*%rnorm(npred))
}
out$draws
addthin
dim(lammean)
50*4
npred
names(out$coords) <- c("Lon", "Lat")
npred <- dim(predloc)[1]
predloc2 <- rbind(out$coords, predloc)
preddist <- as.matrix(dist(predloc2))
condinds <- 1:out$n.locs
lammean <- matrix(0, nrow=floor(out$draws/addthin), ncol=npred)
lamresid <- matrix(0, nrow=floor(out$draws/addthin), ncol=npred)
mycount <- 0
dim(lammean)
seq(1, out$draws, by=addthin)
mycount
dim(lamresid)
for(d in seq(1, out$draws, by=addthin)){
mycount <- mycount + 1
bigmat <- out$tau2.lambda[d,loading]*exp(-preddist/out$phi.lambda[d,loading])
A <- bigmat[condinds, condinds]
B <- bigmat[condinds, -condinds]
C <- bigmat[-condinds, -condinds]
L <- chol(A)
LB <- forwardsolve(t(L), B)
part1 <- t(backsolve(L, LB))
condvar <- C - part1%*%B
lammean[mycount,] <- part1%*%out$Lambda.tilde[d, seq(loading, out$n.factors*out$n.locs, by=out$n.factors)] #((loading-1)*out$n.locs) + (1:out$n.locs)]
cholC <- chol(condvar)
lamresid[mycount,] <- as.numeric(cholC%*%rnorm(npred))
}
pred <- lammean
predloc$predm <- apply(pred, 1, mean)
plot.title = paste0(toupper(substring(type,1,1)), substring(type,2))
type="mean"
plot.title = paste0(toupper(substring(type,1,1)), substring(type,2))
max_value = max(abs(min(predloc$predm)),abs(max(predloc$predm)))
min_value = -max_value
predloc$predm
m <- ggplot2::ggplot(aes(x=Lon, y=Lat, fill=predm), data=predloc) +
#geom_point(aes(x=Lon, y=Lat, color=predm)) +
geom_raster(interpolate=T) +
scale_fill_gradientn(colours=color.gradient, name=legend.name,
limits = c(min_value, max_value)) +
ggtitle(plot.title) + xlab("Longitude") + ylab("Latitude")
color.gradient=colorRampPalette(rev(RColorBrewer::brewer.pal(9, name='RdBu')))(fine)
m <- ggplot2::ggplot(aes(x=Lon, y=Lat, fill=predm), data=predloc) +
#geom_point(aes(x=Lon, y=Lat, color=predm)) +
geom_raster(interpolate=T) +
scale_fill_gradientn(colours=color.gradient, name=legend.name,
limits = c(min_value, max_value)) +
ggtitle(plot.title) + xlab("Longitude") + ylab("Latitude")
print(m)
predloc$predm <- apply(pred, 1, median)
m <- ggplot2::ggplot(aes(x=Lon, y=Lat, fill=predm), data=predloc) +
#geom_point(aes(x=Lon, y=Lat, color=predm)) +
geom_raster(interpolate=T) +
scale_fill_gradientn(colours=color.gradient, name=legend.name,
limits = c(min_value, max_value)) +
ggtitle(plot.title) + xlab("Longitude") + ylab("Latitude")
print(m)
dim(apply(pred, 2, median))
length(apply(pred, 2, median))
length(apply(pred, 1, median))
pred <- t(lammean)
length(apply(pred, 1, median))
predloc$predm <- apply(pred, 1, mean)
m <- ggplot2::ggplot(aes(x=Lon, y=Lat, fill=predm), data=predloc) +
#geom_point(aes(x=Lon, y=Lat, color=predm)) +
geom_raster(interpolate=T) +
scale_fill_gradientn(colours=color.gradient, name=legend.name,
limits = c(min_value, max_value)) +
ggtitle(plot.title) + xlab("Longitude") + ylab("Latitude")
print(m)
max_value = max(abs(min(predloc$predm)),abs(max(predloc$predm)))
min_value = -max_value
print(m)
m <- ggplot2::ggplot(aes(x=Lon, y=Lat, fill=predm), data=predloc) +
#geom_point(aes(x=Lon, y=Lat, color=predm)) +
geom_raster(interpolate=T) +
scale_fill_gradientn(colours=color.gradient, name=legend.name,
limits = c(min_value, max_value)) +
ggtitle(plot.title) + xlab("Longitude") + ylab("Latitude")
print(m)
sf_polygon <- sf::st_sfc(sf::st_polygon(list(as.matrix(map_data_loc[,c(1,2)]))), crs=4326)
sf_polygon <- sf::st_make_valid(sf_polygon)
if(!sf::st_is_valid(sf_polygon)){suppressMessages(sf::sf_use_s2(FALSE))}
### Check if points fall inside of polygon ###
inside = c()
for (kk in 1:nrow(predloc)) {
point = sf::st_sfc(sf::st_point(as.matrix(predloc[kk,c(1,2)])), crs=4326)
if (suppressMessages(sf::st_intersects(point, sf_polygon, sparse=FALSE))) inside = append(inside, kk)
}
predloc.inside = predloc[inside, ]
max_value = max(abs(min(predloc.inside$predm)),abs(max(predloc.inside$predm)))
min_value = -max_value
m = ggplot() +
## First layer: worldwide map
geom_polygon(data = full_map,
aes(x=long, y=lat, group = group),
color = '#9c9c9c', fill = '#f3f3f3') +
## Second layer: Country map
geom_polygon(data = map_data_loc,
aes(x=long, y=lat, group = group),
color = '#9c9c9c', fill='#f3f3f3') +
coord_map() +
coord_fixed(1.3,
xlim = c(min(out$coords[,1])-1, max(out$coords[,1])+1),
ylim = c(min(out$coords[,2])-1, max(out$coords[,2])+1)) +
ggtitle(plot.title) + # FIX ME
theme(panel.background =element_rect(fill = rgb(0.67, .84, .89, .35))) +
#geom_point(data=predloc.inside, aes(x=Lon, y=Lat, color=predm)) +
geom_raster(data=predloc.inside, aes(x=Lon, y=Lat, fill=predm)) +
scale_fill_gradientn(colours=color.gradient, name=legend.name,
limits = c(min_value, max_value)) +
# limits = c(-0.7, 0.7)) + # FIX ME
xlab('Longitude') +
ylab('Latitude')
if(!with.uncertainty){print(m)}
print(m)
library(remotes)
#install.packages('npreg')
#install.packages('scatterplot3d')
install_github("cberrettstat/BSTFA", force=T)
library(BSTFA)
plot.map(out.full, "loading", addthin=25, loading=1, map=T, state=T, location="california", fine=50) #works; but looks funny so need to see if I'm pulling the correct lambda values
library(remotes)
#install.packages('npreg')
#install.packages('scatterplot3d')
install_github("cberrettstat/BSTFA", force=T)
library(BSTFA)
library(lubridate)
library(mvtnorm)
library(tidyverse)
setwd('~/Documents/Research/TempChange/STFAModel/')
data2 <- read.csv('PM2.5_California')
set_1 <- data2 |>
select(local_site_name, arithmetic_mean, quarter, year)|>
mutate(Date = case_when(
quarter == 1 ~ as.Date(paste0(year, "-01-01")),
quarter == 2 ~ as.Date(paste0(year, "-04-01")),
quarter == 3 ~ as.Date(paste0(year, "-07-01")),
quarter == 4 ~ as.Date(paste0(year, "-10-01"))))|>
distinct(local_site_name, Date, .keep_all = TRUE)|>
group_by(Date, local_site_name) |>
summarize(Quarterly_mean = mean(arithmetic_mean))|>
pivot_wider(names_from = local_site_name, values_from = Quarterly_mean) |>
arrange(Date)
date_vector <- set_1$Date
set_1$Date <- NULL
set_1 <- as.matrix(set_1)
set_1[which(set_1==0)] <- rnorm(length(which(set_1==0)), .1, .01)
set_1 <- log(set_1)
#Zero-center the data
for(i in 1:dim(set_1)[2]){
set_1[,i] <- set_1[,i] - mean(set_1[,i], na.rm=T)
}
#Remove locations with >80% missing data
percent_missing <- apply(is.na(set_1), 2, mean)
keep <- which(percent_missing < .8)
set_1 <- set_1[,keep]
set_1 <- set_1[,-1] #location 1 has weird behavior at the end of its observed period so I'm just getting rid of it for now
# Set 2: vector of dates with nrows equal to nrows in ymat
# set_2 <- data2|>
# select(quarter, year)|>
# mutate(Date = case_when(
# quarter == 1 ~ as.Date(paste0(year, "-01-01")),
# quarter == 2 ~ as.Date(paste0(year, "-04-01")),
# quarter == 3 ~ as.Date(paste0(year, "-07-01")),
# quarter == 4 ~ as.Date(paste0(year, "-10-01"))))|>
# distinct(Date) |>
# #make the date a vector of dates
# date_vector <- set_2$Date
#Set 3: df of coordinates with nrows equal to ncols in set_1
set_3 <- data2|>
select(local_site_name, longitude, latitude)|>
distinct(local_site_name, .keep_all = TRUE)
set_3 <- set_3[keep,]
set_3 <- set_3[-1,]
#####################################
# Checking the "full" function
out.full <- BSTFAfull(ymat=set_1, dates=date_vector, coords=set_3[,2:3], iters=1000)
plot.map(out.full, "loading", addthin=25, loading=1, map=T, state=T, location="california", fine=50, with.uncertaint=T) #works; but looks funny so need to see if I'm pulling the correct lambda values
plot.map(out.full, "loading", addthin=25, loading=1, map=T, state=T, location="california", fine=50, with.uncertaint=F) #works; but looks funny so need to see if I'm pulling the correct lambda values
plot.map(out.full, "slope", map=T, state=T, location="california") #doesn't work
out <- out.full
out$spatial.style
plot.title = 'Slope'
predS <- NULL
for(kk in 1:length(out$knots.spatial)) {
bspred <- bisquare2d(as.matrix(predloc), as.matrix(out$knots.spatial[[kk]]))
predS <- cbind(predS, bspred)
}
out$knots.spatial
out$knots
out$knot.levels
length(out$knots)
out$knots
library(remotes)
#install.packages('npreg')
#install.packages('scatterplot3d')
install_github("cberrettstat/BSTFA", force=T)
library(BSTFA)
library(lubridate)
library(mvtnorm)
library(tidyverse)
setwd('~/Documents/Research/TempChange/STFAModel/')
data2 <- read.csv('PM2.5_California')
set_1 <- data2 |>
select(local_site_name, arithmetic_mean, quarter, year)|>
mutate(Date = case_when(
quarter == 1 ~ as.Date(paste0(year, "-01-01")),
quarter == 2 ~ as.Date(paste0(year, "-04-01")),
quarter == 3 ~ as.Date(paste0(year, "-07-01")),
quarter == 4 ~ as.Date(paste0(year, "-10-01"))))|>
distinct(local_site_name, Date, .keep_all = TRUE)|>
group_by(Date, local_site_name) |>
summarize(Quarterly_mean = mean(arithmetic_mean))|>
pivot_wider(names_from = local_site_name, values_from = Quarterly_mean) |>
arrange(Date)
date_vector <- set_1$Date
set_1$Date <- NULL
set_1 <- as.matrix(set_1)
set_1[which(set_1==0)] <- rnorm(length(which(set_1==0)), .1, .01)
set_1 <- log(set_1)
#Zero-center the data
for(i in 1:dim(set_1)[2]){
set_1[,i] <- set_1[,i] - mean(set_1[,i], na.rm=T)
}
#Remove locations with >80% missing data
percent_missing <- apply(is.na(set_1), 2, mean)
keep <- which(percent_missing < .8)
set_1 <- set_1[,keep]
set_1 <- set_1[,-1] #location 1 has weird behavior at the end of its observed period so I'm just getting rid of it for now
# Set 2: vector of dates with nrows equal to nrows in ymat
# set_2 <- data2|>
# select(quarter, year)|>
# mutate(Date = case_when(
# quarter == 1 ~ as.Date(paste0(year, "-01-01")),
# quarter == 2 ~ as.Date(paste0(year, "-04-01")),
# quarter == 3 ~ as.Date(paste0(year, "-07-01")),
# quarter == 4 ~ as.Date(paste0(year, "-10-01"))))|>
# distinct(Date) |>
# #make the date a vector of dates
# date_vector <- set_2$Date
#Set 3: df of coordinates with nrows equal to ncols in set_1
set_3 <- data2|>
select(local_site_name, longitude, latitude)|>
distinct(local_site_name, .keep_all = TRUE)
set_3 <- set_3[keep,]
set_3 <- set_3[-1,]
#####################################
# Checking the "full" function
out.full <- BSTFAfull(ymat=set_1, dates=date_vector, coords=set_3[,2:3], iters=1000)
plot.map(out.full, "slope", map=T, state=T, location="california") #doesn't work
#Error in array(x, c(length(x), 1L), if (!is.null(names(x))) list(names(x),  :
#  'data' must be of a vector type, was 'NULL'
plot.map(out.full, "slope", map=T, state=T, location="california", with.uncertainty=T) #same
plot.location(out.full, location=5, truth=T) #doesn't work
12*5
545+500+1200+150+60
devtools::document()
devtools::document()
library(RColorBrewer)
?brewer.pal
library(BSTFA)
?BSTFA
library(lubridate)
library(mvtnorm)
library(tidyverse)
setwd('~/Documents/Research/TempChange/STFAModel/')
data2 <- read.csv('PM2.5_California')
set_1 <- data2 |>
select(local_site_name, arithmetic_mean, quarter, year)|>
mutate(Date = case_when(
quarter == 1 ~ as.Date(paste0(year, "-01-01")),
quarter == 2 ~ as.Date(paste0(year, "-04-01")),
quarter == 3 ~ as.Date(paste0(year, "-07-01")),
quarter == 4 ~ as.Date(paste0(year, "-10-01"))))|>
distinct(local_site_name, Date, .keep_all = TRUE)|>
group_by(Date, local_site_name) |>
summarize(Quarterly_mean = mean(arithmetic_mean))|>
pivot_wider(names_from = local_site_name, values_from = Quarterly_mean) |>
arrange(Date)
date_vector <- set_1$Date
set_1$Date <- NULL
set_1 <- as.matrix(set_1)
set_1[which(set_1==0)] <- rnorm(length(which(set_1==0)), .1, .01)
set_1 <- log(set_1)
#Zero-center the data
for(i in 1:dim(set_1)[2]){
set_1[,i] <- set_1[,i] - mean(set_1[,i], na.rm=T)
}
#Remove locations with >80% missing data
percent_missing <- apply(is.na(set_1), 2, mean)
keep <- which(percent_missing < .8)
set_1 <- set_1[,keep]
set_1 <- set_1[,-1] #location 1 has weird behavior at the end of its observed period so I'm just getting rid of it for now
# Set 2: vector of dates with nrows equal to nrows in ymat
# set_2 <- data2|>
# select(quarter, year)|>
# mutate(Date = case_when(
# quarter == 1 ~ as.Date(paste0(year, "-01-01")),
# quarter == 2 ~ as.Date(paste0(year, "-04-01")),
# quarter == 3 ~ as.Date(paste0(year, "-07-01")),
# quarter == 4 ~ as.Date(paste0(year, "-10-01"))))|>
# distinct(Date) |>
# #make the date a vector of dates
# date_vector <- set_2$Date
#Set 3: df of coordinates with nrows equal to ncols in set_1
set_3 <- data2|>
select(local_site_name, longitude, latitude)|>
distinct(local_site_name, .keep_all = TRUE)
set_3 <- set_3[keep,]
set_3 <- set_3[-1,]
class(date_vector)
dim(set_3)
class(set_3)
names(set_3)
temp <- 'grid'
class(temp)
0.0000001
library(remotes)
#install.packages('npreg')
#install.packages('scatterplot3d')
install_github("cberrettstat/BSTFA", force=T)
#Sys.seten
library(BSTFA)
?BSTFA
devtools::document()
devtools::document()
devtools::document()
library(RColorBrewer)
?brewer.pal
devtools::document()
devtools::document()
pkgload::dev_help('BSTFA')
names(out)
library(BSTFA)
library(lubridate)
library(mvtnorm)
library(tidyverse)
setwd('~/Documents/Research/TempChange/STFAModel/')
data2 <- read.csv('PM2.5_California')
set_1 <- data2 |>
select(local_site_name, arithmetic_mean, quarter, year)|>
mutate(Date = case_when(
quarter == 1 ~ as.Date(paste0(year, "-01-01")),
quarter == 2 ~ as.Date(paste0(year, "-04-01")),
quarter == 3 ~ as.Date(paste0(year, "-07-01")),
quarter == 4 ~ as.Date(paste0(year, "-10-01"))))|>
distinct(local_site_name, Date, .keep_all = TRUE)|>
group_by(Date, local_site_name) |>
summarize(Quarterly_mean = mean(arithmetic_mean))|>
pivot_wider(names_from = local_site_name, values_from = Quarterly_mean) |>
arrange(Date)
date_vector <- set_1$Date
set_1$Date <- NULL
set_1 <- as.matrix(set_1)
set_1[which(set_1==0)] <- rnorm(length(which(set_1==0)), .1, .01)
set_1 <- log(set_1)
#Zero-center the data
for(i in 1:dim(set_1)[2]){
set_1[,i] <- set_1[,i] - mean(set_1[,i], na.rm=T)
}
#Remove locations with >80% missing data
percent_missing <- apply(is.na(set_1), 2, mean)
keep <- which(percent_missing < .8)
set_1 <- set_1[,keep]
set_1 <- set_1[,-1] #location 1 has weird behavior at the end of its observed period so I'm just getting rid of it for now
# Set 2: vector of dates with nrows equal to nrows in ymat
# set_2 <- data2|>
# select(quarter, year)|>
# mutate(Date = case_when(
# quarter == 1 ~ as.Date(paste0(year, "-01-01")),
# quarter == 2 ~ as.Date(paste0(year, "-04-01")),
# quarter == 3 ~ as.Date(paste0(year, "-07-01")),
# quarter == 4 ~ as.Date(paste0(year, "-10-01"))))|>
# distinct(Date) |>
# #make the date a vector of dates
# date_vector <- set_2$Date
#Set 3: df of coordinates with nrows equal to ncols in set_1
set_3 <- data2|>
select(local_site_name, longitude, latitude)|>
distinct(local_site_name, .keep_all = TRUE)
set_3 <- set_3[keep,]
set_3 <- set_3[-1,]
out <- BSTFA(ymat = set_1,
dates = date_vector,
coords = set_3[,2:3],
iters=500, n.load.bases=4, n.spatial.bases=4, n.temp.bases=20)
#
names(out)
out$mu
names(out)
class(out$mu)
dim(out$mu)
dim(alpha.mu)
dim(out$alpha.mu)
out$n.spatial.bases
names(out)
dim(out$tau2.mu)
dim(out$beta)
dim(out$tau2.beta)
dim(out$xi)
417/139
out$n.spatial.bases
out$spatial.style
names(out)
names(out$model.matrices)
dim(out$model.matrices$newS)
out$n.seasn.knots
dim(out$alpha.xi)
dim(out$tau2.xi)
#####################################
# Checking the "full" function
out.full <- BSTFAfull(ymat=set_1, dates=date_vector, coords=set_3[,2:3], iters=1000)
dim(out.full$tau2.xi)
names(out)
dim(out$alphaT)
dim(out$F.tilde)
dim(out.full$F.tilde)
100*.1
dim(n.temp.bases)
out$n.temp.bases
names(out)
dim(Lambda.tilde)
dim(out$Lambda.tilde)
dim(out.full$Lambda.tilde)
dim(out$alphaS)
out$n.load.bases
dim(out$tau2.lambda)
names(out)
dim(out$missing)
out$missing
names(out)
dim(out$y.missing)
sum(out$missing)
class(out$y.missing)
class(out$alphaS)
temp <- NULL
coda::as.mcmc(t(temp))
coda::as.mcmc(t(as.matrix(temp)))
names(out)
time.data
class(out$time.data)
dim(out$time.data)
head(out$time.data)
names(out)
class(setup.time)
class(out$setup.time)
out$setup.time
class(out$model.matrices)
names(out$model.matrices)
dim(out$model.matrices$linear.Tsub)
names(out)
out$factors.fixed
class(out$factors.fixed)
names(out)
dim(out$y)
length(out$y)
dim(out$ymat)
class(out$y)
class(out$doy)
names(out)
?utahDataList
temp <- data(utahDataList)
names(temp)
temp
names(utahDataList)
devtools::document()
devtools::document()
library(remotes)
#install.packages('npreg')
#install.packages('scatterplot3d')
install_github("cberrettstat/BSTFA", force=T)
library(BSTFA)
?BSTFA
